---
layout: post
title:  "Real-time Object Detection Using Faster R-CNNs"
date:   2018-04-20 
categories: [Deep Learning, Object-detection, Python]
comments : true
---

<ul id="toc"></ul>

---

## Introduction

In this post we will talk about the object detection system using Faster R-CNN propsoed by _Ren et. al._ in 2015. Faster R-CNNs are made up of two modules. The first one is a fully convolutional network called the Region Proposal Network (**RPN**) and the second module is the Fast R-CNN detector that uses the proposed regions for classification. The entire system is one single combined system for object detection. The RPN module tell the R-CNN where to look. The following figure shows the Faster R-CNN.

{% include image.html
   img="/data/faster-r-cnn/images/faster-r-cnn-model.jpg"
   caption="Faster R-CNN is a single network consisting of 2 modules. The RPN modules serves as the 'attention' for the unified network. [Source](https://arxiv.org/abs/1506.01497)"
%}


## Faster R-CNN

Now we talk about the different componenets of the Faster R-CNN in detail

### Region Proposal Networks
An RPN takes as input an image and returns a set of rectangles, these are the object proposals and each of them has a objectness score. This is done using a fully convolutional network, which shares some layers with a Fast R-CNN object detection network. The regions are generated by using a small network over the convolutional feature map. This feature map is the output of the last shared convolutional layer. The small network takes as input a _n x n_ region of the feature map, which is then mapped to a lower-dimension feature with 256 layers (filters), _256-d_. These are input into two parallel fully connected layer, a box-regression layer (_reg_) and a box-classification layer (_cls_). _Ren et.al_ take the value _n = 3_ for their paper. This mini-network consists of a _n x n_ convolutional layer, followed by two sibling convolutional _1 x 1_ layers, the _reg_ and _cls_ respectively. 

### Anchors

For each sliding window, the networks makes multiple simulatneous proposals, where is the number of proposals for each sliding window location is _k_. The _reg_ layer gives _4k_ outputs containing the coordinates of the _k_ boxes and the _cls_ layer had _2k_ scores that estimate the probablity of being an object or not object for each proposal. These _k_ proposals are estimated from _k_ reference boxes, which are called _anchors_.  An anchor for a given sliding window, has a scale and aspect ratio associated with it, in their paper _Ren et. al_ have used 3 scales and 3 aspect ratios, this yeilds 9 anchors at each sliding window location. For a convolutional feature map of size _w x h_ the total number of anchors = _w x h x k_.

<!-- #### Transition-Invariant Anchors
 -->



## References
[1] Ren, Shaoqing, et al. "Faster r-cnn: Towards real-time object detection with region proposal networks." Advances in neural information processing systems. 2015.

[paper]: https://arxiv.org/abs/1506.01497
[code]:  https://github.com/KaimingHe/deep-residual-networks

